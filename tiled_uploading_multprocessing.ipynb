{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bd72742-25b2-44cb-af75-842038993673",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/bin/python\n",
      "Fri Mar 29 14:34:42 2024\n"
     ]
    }
   ],
   "source": [
    "from tiled.client import from_uri, from_profile\n",
    "from tiled.structures.table import TableStructure\n",
    "from tiled.structures.data_source import DataSource\n",
    "from tiled.structures.core import StructureFamily\n",
    "from tpx3utils import extract_fpaths_from_sid, raw_to_sorted_df, raw_df_to_cluster_df, add_centroid_cols\n",
    "from tqdm import tqdm\n",
    "import tiled as td\n",
    "import os\n",
    "import multiprocessing\n",
    "import sys\n",
    "import time\n",
    "print(sys.executable)\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92d4f0be-41e6-43f9-ac43-f43705802d90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# client objects\n",
    "db_raw = from_uri('https://tiled.nsls2.bnl.gov', 'dask')['chx']['raw']\n",
    "db_proc = from_uri('https://tiled.nsls2.bnl.gov', 'dask')['chx']['processed']\n",
    "\n",
    "# function that uses filename to obtain both uncentroided and centroided dataframes\n",
    "def source_dfs(filename):\n",
    "    uncentdf = raw_to_sorted_df(filename)\n",
    "    centdf = add_centroid_cols(raw_df_to_cluster_df(uncentdf))\n",
    "    return (uncentdf, centdf)\n",
    "            \n",
    "# multiprocessing function for uploading each partition in parallel\n",
    "def upload_partition(args):\n",
    "    # partition number, filename, uncent node, cent node\n",
    "    partition_num = args[0]\n",
    "    file_path = args[1]\n",
    "    uncent_node = args[2]\n",
    "    cent_node = args[3]\n",
    "    \n",
    "    if (os.path.exists(file_path)):\n",
    "        # check and see if file_path exists first before sourcing dfs.\n",
    "        dfs = source_dfs(file_path)\n",
    "        # catching WriteError that occurs with Tiled sometimes\n",
    "        while (True):\n",
    "            try:\n",
    "                uncent_node.write_partition(dfs[0], partition_num)\n",
    "                cent_node.write_partition(dfs[1], partition_num)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            \n",
    "            \n",
    "# defines a new container in tiled and writes all data from run object\n",
    "def insert_to_tiled(container, run):    \n",
    "    num_img = run['primary'].metadata['descriptors'][0]['configuration']['tpx3']['data']['tpx3_cam_num_images']\n",
    "    raw_file_paths = run['primary']['data']['tpx3_files_raw_filepaths'][0].compute()\n",
    "    \n",
    "    # create new container, nodes, and write first dataframes\n",
    "    # must do this because structure needs an example dataframe\n",
    "    uid = run['primary'].metadata['descriptors'][0]['run_start']\n",
    "    dfs = source_dfs(raw_file_paths[0][5:])\n",
    "    uncent_structure = TableStructure.from_pandas(dfs[0])\n",
    "    cent_structure = TableStructure.from_pandas(dfs[1])\n",
    "    uncent_structure.npartitions = num_img\n",
    "    cent_structure.npartitions = num_img\n",
    "    \n",
    "    # name of key for testing purposes, should be using version on next line\n",
    "    scan_container = db_proc.create_container(key='test_mp14_{}'.format(uid), metadata={\"raw_uid\": uid, \"raw_sid\": run.metadata['start']['scan_id']})\n",
    "    # scan_container = db_proc.create_container(key=run.start['uid'], metadata={\"raw_uid\": run.start['uid'], \"raw_sid\": run.start['scan_id']})\n",
    "    \n",
    "    # create cent and uncent containers\n",
    "    uncent_node = scan_container.new(\"table\", [DataSource(structure=uncent_structure, structure_family=StructureFamily.table),], key=\"uncent\")\n",
    "    cent_node = scan_container.new(\"table\", [DataSource(structure=cent_structure, structure_family=StructureFamily.table),], key=\"cent\")\n",
    "    uncent_node.write_partition(dfs[0], 0)\n",
    "    cent_node.write_partition(dfs[1], 0)\n",
    "    \n",
    "    # gather arguments for each partition\n",
    "    args = []\n",
    "    for i in range(1, num_img):\n",
    "        args.append([i, raw_file_paths[i][5:], uncent_node, cent_node])\n",
    "        \n",
    "    # multiprocessing pool\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    max_workers = num_cores-1\n",
    "    \n",
    "    with multiprocessing.Pool(processes=max_workers) as pool:\n",
    "        pool.map(upload_partition, tqdm(args))\n",
    "\n",
    "# take in a list of sids and upload them all to tiled\n",
    "def sids_to_tiled(sids):\n",
    "    for sid in sids:\n",
    "        insert_to_tiled(db_proc, db_raw[sid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfa602be-1bac-4bf6-861f-3e59f23fe48b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [20:19<00:00,  1.02s/it] \n"
     ]
    }
   ],
   "source": [
    "# demo\n",
    "insert_to_tiled(db_proc, db_raw[143210])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python /srv/conda",
   "language": "python",
   "name": "new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
